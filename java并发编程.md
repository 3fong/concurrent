## Java 并发编程

- 并行与并发

并发（Concurrent）:同一时间只能有一个线程执行的状态,存在资源竞争.当有多个线程在操作时，如果系统只有一个 CPU，则它根本不可能真正同时进行一个以上的线程，它只能把 CPU 运行时间划分成若干个时间段，再将时间段分配给各个线程执行，在一个时间段的线程代码运行时,其它线程处于挂起状态.这种方式我们称之为并发。

并行（Parallel）:同一时间多个线程一起执行的状态,不存在资源竞争.当系统有一个以上 CPU 时，则线程的操作有可能非并发。当一个 CPU 执行一个线程时，另一个 CPU 可以执行另一个线程，两个线程互不抢占 CPU资源，可以同时进行，这种方式我们称之为并行。

### 并发

并发的价值:

1. 方便的通信和数据交换.比进程间通信更方便
线程间有方便的通信和数据交换机制。对于不同进程来说，它们具有独立的数据空间，要进行数据的传递只能通过通信的方式进行，这种方式不仅费时，而且很不方便。线程则不然，由于同一进程下的线程之间共享数据空间，所以一个线程的数据可以直接为其他线程所用，这不仅快捷，而且方便。
2. 更高效地利用CPU
3. 防止线程“堵塞”，增强用户体验和程序的效率。

缺点:

1. 代码的复杂程度会大大提高
2. 对于硬件的要求也相应地提高

并发衡量指标:并发数

TPS(Transactions Per Second): 每秒的事务处理数量，简而言之：用户请求页面->服务器进行处理->用户收到结果（这是一个TPS）    
QPS(Queries Per Second):每秒处理的查询数量：1000个用户同时查询一个商品，1000个用户同时可以查询到信息，那么我们的1000QPS/S

并发实现方式:

1. 提高硬件配置
2. 多线程

问题:

并发并不是一定能让程序更快,它有如下的限制:

1. 上下文切换
2. 死锁
3. 软硬的限制

并发问题

#### 上下文切换

1. 多线程
并发执行机制原理: 简单地说就是把一个处理器划分为若干个短的时间片，每个时间片依次轮流地执行处理各个应用程序，由于一个时间片很短，相对于一个应用程序来说，就好像是处理器在为自己单独服务一样，从而达到多个应用程序在同时进行的效果.

多线程:把操作系统中的这种并发执行机制原理运用在一个程序中，把一个程序划分为若干个子任务，多个子任务并发执行，每一个任务就是一个线程.Java中线程与系统线程是一对一的关系.

因此时间片的切换需要进行上下文切换,来获取线程的执行状态.这个切换会影响执行效率,也影响线程执行速度.也因此线程并不是越多越好,实际的执行效率受线程创建与上下文切换的影响.

2. 如何减少上下文切换

```
无锁编程(分段锁,通过规则约定降低线程资源竞争造成线程切换)
CAS算法(通过软件支持的原子性操作解决资源竞争问题,避免线程切换)
减少线程数
使用协程
```

协程:单线程多任务的共享资源管理方式.运行在线程之上，当一个协程执行完成后，可以选择主动让出，让另一个协程运行在当前线程之上。协程并没有增加线程数量，只是在线程的基础之上通过分时复用的方式运行多个协程，而且协程的切换在用户态完成，切换的代价比线程从用户态到内核态的代价小很多。
如:本身要创建100个线程的任务,可以创建10个线程,每个线程起10个协程来执行此任务.
```
在有大量IO操作业务的情况下，我们采用协程替换线程，可以到达很好的效果，一是降低了系统内存，二是减少了系统切换开销，因此系统的性能也会提升。    
在协程中尽量不要调用阻塞IO的方法，比如打印，读取文件，Socket接口等，除非改为异步调用的方式，并且协程只有在IO密集型的任务中才会发挥作用。    
协程只有和异步IO结合起来才能发挥出最大的威力。
```

jstatck;vmstat

#### 死锁

多个线程间互相持有锁,造成的占用资源无法释放的现象.

减少死锁方式
```
避免一个线程同时获取多个锁
避免一个线程在锁内同时占用多个资源,尽量保证每个锁只占用一个资源    
尝试使用定时锁    
数据库锁,加锁和解锁必须在一个数据库连接里,避免解锁失败
```


#### 软硬的限制

硬件限制:带宽,磁盘读写速度,内存,cpu处理速度;    
软件限制:数据库连接数,socket连接数

当资源限制较大时,并行由于相对于串行增加了上下文切换和资源调度时间,会更加慢.

解决方式:

1. 硬件限制.使用集群来扩展硬件资源.
2. 软件限制. 使用资源池,实现资源复用.
3. 多种限制因素时,要综合考虑限制点,评估最终的使用方式


### Java并发机制

并发只是一种提高程序运行效率的机制,而程序的核心价值在于正确的得到自己想要的结果.效率只是基于这个结果上的一种优化,一个错误的结果只能是垃圾.所以获得效率必须保证结果的正确性.
并发的价值在于可以调高非共享资源的使用效率,而对于共享资源则存在资源竞争问题,由于并发机制的复杂性,竞争会造成获取资源的正确性产生问题.

并发机制的运用为了保证正确性,需要从如下几个方面入手:

```
原子性: 分时复用引起    
可见性: CPU和缓存引起    
有序性: cpu的乱序执行和编译器的指令重排序引起    
```

编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。
指令级并行的重排序。现代处理器采用了指令级并行技术（Instruction-Level Parallelism， ILP）来将多条指令重叠
执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。

具体的实现方式:

1. 锁.将并发改成串行,根本上解决共享资源竞争.竞争越激烈,并发效率越低
2. ....


- 线程与进程

进程：是代码在数据集合上的一次运行活动，是系统进行资源分配和调度的基本单位。

线程：是进程的一个执行路径，一个进程中至少有一个线程，进程中的多个线程共享进程的资源。
虽然系统是把资源分给进程，但是CPU很特殊，是被分配到线程的，所以线程是CPU分配的基本单位。

![java线程模型](https://img2018.cnblogs.com/blog/1271254/201907/1271254-20190706220449848-1411965352.png)

二者关系：    
一个进程中有多个线程，多个线程共享进程的堆和方法区资源，但是每个线程有自己的程序计数器和栈区域。
```
程序计数器：是一块内存区域，用来记录线程当前要执行的指令地址 。
栈：用于存储该线程的局部变量，这些局部变量是该线程私有的，除此之外还用来存放线程的调用栈祯。
堆：是一个进程中最大的一块内存，堆是被进程中的所有线程共享的。
方法区：则用来存放 NM 加载的类、常量及静态变量等信息，也是线程共享的 。
```
二者区别：    
进程：有独立的地址空间，一个进程崩溃后，在保护模式下不会对其它进程产生影响。
线程：是一个进程中的不同执行路径。线程有自己的堆栈和局部变量，但线程之间没有单独的地址空间，一个线程死掉就等于整个进程死掉。


- 并发与并行

并发：是指同一个时间段内多个任务同时都在执行，并且都没有执行结束。并发任务强调在一个时间段内同时执行，而一个时间段由多个单位时间累积而成，所以说并发的多个任务在单位时间内不一定同时在执行。    
并行：是说在单位时间内多个任务同时在执行。
在多线程编程实践中，线程的个数往往多于CPU的个数，所以一般都称多线程并发编程而不是多线程并行编程。

Java为了实现多线程同时为了屏蔽操作系统差异,提取自己的内存模型,来规范Java的线程定义,以及内存资源的读写操作.

所以Java中的并发问题指的就是基于Java内存模型下的多线程间资源共享问题.

常见的解决方式如下:

```
volatile
final
synchronized
lock
```

#### volatile

volatile是轻量级的 synchronized,保证共享资源的可见性.    
可见性指当一个线程修改共享变量时,其他线程可以读到这个修改值.    
由于它不需要切换上下文和调度,所以执行成本比synchronized低.

volatile: 更新时通过排他锁单独获取这个变量.java线程内存模型确保所有线程看到的共享值是一致的.

- 原理

CPU并发相关术语

| 术语 | 英文 | 解释 |
| ---- | ---- | ---- |
| 内存屏障 | memory barriers | 是一组处理器指令，用于实现对内存操作的顺序限制 |
| 缓冲行 | cache line | CPU 高速缓存中可以分配的最小存储单元。处理器填写缓存行时会加载整个缓存行，现代CPU需要执行几百次CPU执行 |
| 原子操作 | atomic operations | 不可中断的一个或者一系列操作 |
| 缓存行填充 | cache line fill | 当处理器识别到从内存中读取操作数是可缓存的，处理器读取整个高速缓存行到适当的缓存（L1,| L2,L3 的或所有） |
| 缓存命中 | cache hit | 如果进行高速缓存行填充操作的内存位置仍然是下次处理器访问的地址时，处理器从缓存中读取操作数，而不是从内存中读取。 |
| 写命中 | write hit | 当处理器将操作数写回到一个内存缓存的区域时，它首先会检查这个缓存的内存地址是否存在缓存行中，如果存在一个有效的缓存行，则处理器将这个操作数写回到缓存，而不是写回到内存，这个操作被称为写命中 |
| 写缺失 | write misses the cache | 一个有效的缓存行被写入到不存在的内存区域 |
| 比较并交换 | Compare and swap | CAS 操作需要输入两个值，一个旧值（期望操作前的值）和一个新值，在操作期间先比较旧值有没有发生变化，如果没有发生变化，才交换成新值，发生了变化则不交换。 |
| Cpu 流水线 | CPU pipeline | 在CPU中由5-6个不同功能的电路单元组成一条指令处理流水线，然后将一条X86指令分成 5-6 步后再由这些电路单元分别执行，实现在一个CPU时钟周期完成一条指令。 |
| 内存顺序冲突 | Memory order violation | 由假共享引起，多个CPU同时修改同一个缓存行的不同部分而引起其中一个CPU的操作无效。出现时，必须清空流水线。 |

volatile原理:     
为了提高处理速度,CPU不会直接与内存通信,而是先将系统内存的数据读到内部缓存(L1,L2)后再进行操作,但操作完写回内存操作不定时.    
如果变量声明为volatile,jvm会向CPU发送一条Lock前缀指令,将这个变量所在缓存行的数据写回到内存.同时,多CPU下会实现缓存一致性协议,每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是否过期,当CPU发现自己缓存行对应的内存地址被修改,就会将当前CPU的缓存行设置为无效状态,当CPU对这个数据进行修改操作时,会重新从内存数据读取到CPU缓存中.

Lock指令作用:

1. 引起处理器缓存回写到内存.lock声言该信号期间,处理器独占任何共享内存.实现方式:锁总线;锁CPU缓存(缓存锁定,推荐,成本低),通过缓存一致性协议保证阻止同时修改两个以上处理器缓存的内存区域数据
2. 一个处理器缓存回写到内存会导致其他处理器的缓存失效.CPU嗅探到其他CPU进行缓存回写操作,会使共享变量状态的缓存行无效,下次访问同一个内存地址时,强制执行缓存行填充


#### 缓存一致性协议（MESI）:    

cpu执行计算的主要流程:    
![cpu执行计算的主要流程](https://img2018.cnblogs.com/i-beta/1195936/201912/1195936-20191230144550486-2108138734.png)


数据加载的流程如下：

1.将程序和数据从硬盘加载到内存中
2.将程序和数据从内存加载到缓存中(目前多三级缓存，数据加载顺序:L3->L2->L1)
3.CPU将缓存中的数据加载到寄存器中，并进行运算
4.CPU会将数据刷新回缓存，并在一定的时间周期之后刷新回内存

现在的CPU基本都是多核CPU，服务器更是提供了多CPU的支持，而每个核心也都有自己独立的缓存，当多个核心同时操作多个线程对同一个数据进行更新时，如果核心2在核心1还未将更新的数据刷回内存之前读取了数据，并进行操作，就会造成程序的执行结果造成随机性的影响，这对于我们来说是无法容忍的。
而总线加锁是对整个内存进行加锁，在一个核心对一个数据进行修改的过程中，其他的核心也无法修改内存中的其他数据，这样对导致CPU处理性能严重下降。
缓存一致性协议提供了一种高效的内存数据管理方案，它只会对单个缓存行（缓存行是缓存中数据存储的基本单元）的数据进行加锁，不会影响到内存中其他数据的读写。

缓存一致性协议（MESI）    
缓存一致性协议是一种缓存行状态管理机制,便于保证共享变量在CPU间的可见性.有MSI，MESI，MOSI，Synapse，Firefly及DragonProtocol等等，接下来我们主要介绍MESI协议。

MESI分别代表缓存行数据所处的四种状态，通过对这四种状态的切换，来达到对缓存数据进行管理的目的。

| 状态 | 描述 | 监听任务 | 
| ---- | ---- | ---- |
| M 修改（Modify） | 该缓存行有效，数据被修改了，和内存中的数据不一致，数据只存在于本缓存行中 | 缓存行必须时刻监听所有试图读该缓存行相对应的内存的操作，其他缓存须在本缓存行写回内存并将状态置为E之后才能操作该缓存行对应的内存数据 | 
| E 独享、互斥（Exclusive） | 该缓存行有效，数据和内存中的数据一致，数据只存在于本缓存行中 | 缓存行必须监听其他缓存读主内存中该缓存行相对应的内存的操作，一旦有这种操作，该缓存行需要变成S状态 | 
| S 共享（Shared） | 该缓存行有效，数据和内存中的数据一致，数据同时存在于其他缓存中 | 缓存行必须监听其他缓存是该缓存行无效或者独享该缓存行的请求，并将该缓存行置为I状态 | 
| I 无效（Invalid） | 该缓存行数据无效	 | 无 | 

备注：

```
1.MESI协议只对汇编指令中执行加锁操作的变量有效，表现到java中为使用voliate关键字定义变量或使用加锁操作
2.对于汇编指令中执行加锁操作的变量，MESI协议在以下两种情况中也会失效：
     一、CPU不支持缓存一致性协议。
     二、该变量超过一个缓存行的大小，缓存一致性协议是针对单个缓存行进行加锁，此时，缓存一致性协议无法再对该变量进行加锁，只能改用总线加锁的方式。
3. MESI协议只能保证并发编程中的可见性，并未解决原子性和有序性的问题，所以只靠MESI协议是无法完全解决多线程中的所有问题.
```

[缓存一致性协议分析](https://www.cnblogs.com/ynyhl/p/12119690.html)


#### synchronized

解决共享资源的原子性和有序性,因为是独占共享资源,所以不涉及可见性问题.

锁的表现形式:

```
普通方法->锁是当前示例对象
静态方法->锁是当前类的Class对象
同步方法块->锁是Synchronized指定的对象
```

synchronized要求线程访问同步代码块时,首先先获取锁,退出或异常时释放锁.

- 实现原理

JVM基于进入和退出Monitor对象来实现方法同步和代码块同步,两者实现细节不一样.    
代码块同步:使用monitorenter和monitorexit指令实现.    
方法同步的实现细节JVM规范中未提及,但是它可以使用代码块同步的方式来实现.

monitorenter: 在编译后插入到同步代码块的开始位置.
monitorexit:插入到方法结束或异常处.
JVM保证monitorenter和monitorexit成对匹配.任何对象都有一个monitor与之关联,当且一个monitor被持有后,它将处于锁定状态.     
线程执行到monitorenter指令时,将会尝试获取对象所对应的monitor的所有权,即尝试获取对象的锁.


- 对象头


- 锁升级


#### 原子操作


















