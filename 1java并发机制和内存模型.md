## Java 并发编程

- 并行与并发

并发（Concurrent）:同一时间只能有一个线程执行的状态,存在资源竞争.当有多个线程在操作时，如果系统只有一个 CPU，则它根本不可能真正同时进行一个以上的线程，它只能把 CPU 运行时间划分成若干个时间段，再将时间段分配给各个线程执行，在一个时间段的线程代码运行时,其它线程处于挂起状态.这种方式我们称之为并发。

并行（Parallel）:同一时间多个线程一起执行的状态,不存在资源竞争.当系统有一个以上 CPU 时，则线程的操作有可能非并发。当一个 CPU 执行一个线程时，另一个 CPU 可以执行另一个线程，两个线程互不抢占 CPU资源，可以同时进行，这种方式我们称之为并行。

### 并发

并发的价值:

1. 方便的通信和数据交换.比进程间通信更方便
线程间有方便的通信和数据交换机制。对于不同进程来说，它们具有独立的数据空间，要进行数据的传递只能通过通信的方式进行，这种方式不仅费时，而且很不方便。线程则不然，由于同一进程下的线程之间共享数据空间，所以一个线程的数据可以直接为其他线程所用，这不仅快捷，而且方便。
2. 更高效地利用CPU
3. 防止线程“堵塞”，增强用户体验和程序的效率。

缺点:

1. 代码的复杂程度会大大提高
2. 对于硬件的要求也相应地提高

并发衡量指标:并发数

TPS(Transactions Per Second): 每秒的事务处理数量，简而言之：用户请求页面->服务器进行处理->用户收到结果（这是一个TPS）    
QPS(Queries Per Second):每秒处理的查询数量：1000个用户同时查询一个商品，1000个用户同时可以查询到信息，那么我们的1000QPS/S

并发实现方式:

1. 提高硬件配置
2. 多线程

问题:

并发并不是一定能让程序更快,它有如下的限制:

1. 上下文切换
2. 死锁
3. 软硬的限制

并发问题

#### 上下文切换

1. 多线程
并发执行机制原理: 简单地说就是把一个处理器划分为若干个短的时间片，每个时间片依次轮流地执行处理各个应用程序，由于一个时间片很短，相对于一个应用程序来说，就好像是处理器在为自己单独服务一样，从而达到多个应用程序在同时进行的效果.

多线程:把操作系统中的这种并发执行机制原理运用在一个程序中，把一个程序划分为若干个子任务，多个子任务并发执行，每一个任务就是一个线程.Java中线程与系统线程是一对一的关系.

因此时间片的切换需要进行上下文切换,来获取线程的执行状态.这个切换会影响执行效率,也影响线程执行速度.也因此线程并不是越多越好,实际的执行效率受线程创建与上下文切换的影响.

2. 如何减少上下文切换

```
无锁编程(分段锁,通过规则约定降低线程资源竞争造成线程切换)
CAS算法(通过软件支持的原子性操作解决资源竞争问题,避免线程切换)
减少线程数
使用协程
```

协程:单线程多任务的共享资源管理方式.运行在线程之上，当一个协程执行完成后，可以选择主动让出，让另一个协程运行在当前线程之上。协程并没有增加线程数量，只是在线程的基础之上通过分时复用的方式运行多个协程，而且协程的切换在用户态完成，切换的代价比线程从用户态到内核态的代价小很多。
如:本身要创建100个线程的任务,可以创建10个线程,每个线程起10个协程来执行此任务.
```
在有大量IO操作业务的情况下，我们采用协程替换线程，可以到达很好的效果，一是降低了系统内存，二是减少了系统切换开销，因此系统的性能也会提升。    
在协程中尽量不要调用阻塞IO的方法，比如打印，读取文件，Socket接口等，除非改为异步调用的方式，并且协程只有在IO密集型的任务中才会发挥作用。    
协程只有和异步IO结合起来才能发挥出最大的威力。
```

jstatck;vmstat

#### 死锁

多个线程间互相持有锁,造成的占用资源无法释放的现象.

减少死锁方式
```
避免一个线程同时获取多个锁
避免一个线程在锁内同时占用多个资源,尽量保证每个锁只占用一个资源    
尝试使用定时锁    
数据库锁,加锁和解锁必须在一个数据库连接里,避免解锁失败
```


#### 软硬件的限制

硬件限制:带宽,磁盘读写速度,内存,cpu处理速度;    
软件限制:数据库连接数,socket连接数

当资源限制较大时,并行由于相对于串行增加了上下文切换和资源调度时间,会更加慢.

解决方式:

1. 硬件限制.使用集群来扩展硬件资源.
2. 软件限制. 使用资源池,实现资源复用.
3. 多种限制因素时,要综合考虑限制点,评估最终的使用方式


### Java并发机制

并发只是一种提高程序运行效率的机制,而程序的核心价值在于正确的得到自己想要的结果.效率只是基于这个结果上的一种优化,一个错误的结果只能是垃圾.所以获得效率必须保证结果的正确性.
并发的价值在于可以调高非共享资源的使用效率,而对于共享资源则存在资源竞争问题,由于并发机制的复杂性,竞争会造成获取资源的正确性产生问题.

CPU、内存、I/O设备三者速度差异一直是 核心矛盾 三者速度差异可形象描述为：天上一天(CPU)，地上一年(内存)，地上十年(I/O) 根据木桶理论.
为了合理利用CPU的高性能，平衡三者的速度差异，计算机体系结构、操作系统、编译程序都做了努力：

CPU增加了缓存，以均衡与内存的速度差异    
操作系统增加了进程、线程，以及分时复用CPU，进而均衡CPU与I/O设备的速度差异    
编译程序优化指令执行次序，使得缓存能够得到更加合理的利用    

并发机制的运用为了保证正确性,需要从如下几个方面入手:

```
原子性: 分时复用引起(分时复用(Time Division Multiplexing)是采用同一物理连接的不同时段来传输不同的信号，能达到多路传输的目的。)    
可见性: CPU和缓存引起    
有序性: cpu的乱序执行和编译器的指令重排序引起    
```

编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。
指令级并行的重排序。现代处理器采用了指令级并行技术（Instruction-Level Parallelism， ILP）来将多条指令重叠
执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。

具体的实现方式:

1. 锁.将并发改成串行,根本上解决共享资源竞争.竞争越激烈,并发效率越低
2. ....


- 线程与进程

进程：是代码在数据集合上的一次运行活动，是系统进行资源分配和调度的基本单位。

线程：是进程的一个执行路径，一个进程中至少有一个线程，进程中的多个线程共享进程的资源。
虽然系统是把资源分给进程，但是CPU很特殊，是被分配到线程的，所以线程是CPU分配的基本单位。

![java线程模型](https://img2018.cnblogs.com/blog/1271254/201907/1271254-20190706220449848-1411965352.png)

二者关系：    
一个进程中有多个线程，多个线程共享进程的堆和方法区资源，但是每个线程有自己的程序计数器和栈区域。
```
程序计数器：是一块内存区域，用来记录线程当前要执行的指令地址 。
栈：用于存储该线程的局部变量，这些局部变量是该线程私有的，除此之外还用来存放线程的调用栈祯。
堆：是一个进程中最大的一块内存，堆是被进程中的所有线程共享的。
方法区：则用来存放 NM 加载的类、常量及静态变量等信息，也是线程共享的 。
```
二者区别：    
进程：有独立的地址空间，一个进程崩溃后，在保护模式下不会对其它进程产生影响。
线程：是一个进程中的不同执行路径。线程有自己的堆栈和局部变量，但线程之间没有单独的地址空间，一个线程死掉就等于整个进程死掉。


- 并发与并行

并发：是指同一个时间段内多个任务同时都在执行，并且都没有执行结束。并发任务强调在一个时间段内同时执行，而一个时间段由多个单位时间累积而成，所以说并发的多个任务在单位时间内不一定同时在执行。    
并行：是说在单位时间内多个任务同时在执行。
在多线程编程实践中，线程的个数往往多于CPU的个数，所以一般都称多线程并发编程而不是多线程并行编程。

Java为了实现多线程同时为了屏蔽操作系统差异,提取自己的内存模型,来规范Java的线程定义,以及内存资源的读写操作.

所以Java中的并发问题指的就是基于Java内存模型下的多线程间资源共享问题.

常见的解决方式如下:

```
volatile
final
synchronized
lock
```

#### volatile

volatile是轻量级的 synchronized,保证共享资源的可见性.    
可见性指当一个线程修改共享变量时,其他线程可以读到这个修改值.    
由于它不需要切换上下文和调度,所以执行成本比synchronized低.

volatile: 更新时通过排他锁单独获取这个变量.java线程内存模型确保所有线程看到的共享值是一致的.

- 原理

CPU并发相关术语

| 术语 | 英文 | 解释 |
| ---- | ---- | ---- |
| 内存屏障 | memory barriers | 是一组处理器指令，用于实现对内存操作的顺序限制 |
| 缓冲行 | cache line | CPU 高速缓存中可以分配的最小存储单元。处理器填写缓存行时会加载整个缓存行，现代CPU需要执行几百次CPU执行 |
| 原子操作 | atomic operations | 不可中断的一个或者一系列操作 |
| 缓存行填充 | cache line fill | 当处理器识别到从内存中读取操作数是可缓存的，处理器读取整个高速缓存行到适当的缓存（L1,| L2,L3 的或所有） |
| 缓存命中 | cache hit | 如果进行高速缓存行填充操作的内存位置仍然是下次处理器访问的地址时，处理器从缓存中读取操作数，而不是从内存中读取。 |
| 写命中 | write hit | 当处理器将操作数写回到一个内存缓存的区域时，它首先会检查这个缓存的内存地址是否存在缓存行中，如果存在一个有效的缓存行，则处理器将这个操作数写回到缓存，而不是写回到内存，这个操作被称为写命中 |
| 写缺失 | write misses the cache | 一个有效的缓存行被写入到不存在的内存区域 |
| 比较并交换 | Compare and swap | CAS 操作需要输入两个值，一个旧值（期望操作前的值）和一个新值，在操作期间先比较旧值有没有发生变化，如果没有发生变化，才交换成新值，发生了变化则不交换。 |
| Cpu 流水线 | CPU pipeline | 在CPU中由5-6个不同功能的电路单元组成一条指令处理流水线，然后将一条X86指令分成 5-6 步后再由这些电路单元分别执行，实现在一个CPU时钟周期完成一条指令。 |
| 内存顺序冲突 | Memory order violation | 由假共享引起，多个CPU同时修改同一个缓存行的不同部分而引起其中一个CPU的操作无效。出现时，必须清空流水线。 |

volatile原理:     
为了提高处理速度,CPU不会直接与内存通信,而是先将系统内存的数据读到内部缓存(L1,L2)后再进行操作,但操作完写回内存操作不定时.    
如果变量声明为volatile,jvm会向CPU发送一条Lock前缀指令,将这个变量所在缓存行的数据写回到内存.同时,多CPU下会实现缓存一致性协议,每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是否过期,当CPU发现自己缓存行对应的内存地址被修改,就会将当前CPU的缓存行设置为无效状态,当CPU对这个数据进行修改操作时,会重新从内存数据读取到CPU缓存中.

Lock指令作用:

1. 引起处理器缓存回写到内存.lock声言该信号期间,处理器独占任何共享内存.实现方式:锁总线;锁CPU缓存(缓存锁定,推荐,成本低),通过缓存一致性协议保证阻止同时修改两个以上处理器缓存的内存区域数据
2. 一个处理器缓存回写到内存会导致其他处理器的缓存失效.CPU嗅探到其他CPU进行缓存回写操作,会使共享变量状态的缓存行无效,下次访问同一个内存地址时,强制执行缓存行填充


#### 缓存一致性协议（MESI）:    

cpu执行计算的主要流程:    
![cpu执行计算的主要流程](https://img2018.cnblogs.com/i-beta/1195936/201912/1195936-20191230144550486-2108138734.png)


数据加载的流程如下：

1.将程序和数据从硬盘加载到内存中
2.将程序和数据从内存加载到缓存中(目前多三级缓存，数据加载顺序:L3->L2->L1)
3.CPU将缓存中的数据加载到寄存器中，并进行运算
4.CPU会将数据刷新回缓存，并在一定的时间周期之后刷新回内存

现在的CPU基本都是多核CPU，服务器更是提供了多CPU的支持，而每个核心也都有自己独立的缓存，当多个核心同时操作多个线程对同一个数据进行更新时，如果核心2在核心1还未将更新的数据刷回内存之前读取了数据，并进行操作，就会造成程序的执行结果造成随机性的影响，这对于我们来说是无法容忍的。
而总线加锁是对整个内存进行加锁，在一个核心对一个数据进行修改的过程中，其他的核心也无法修改内存中的其他数据，这样对导致CPU处理性能严重下降。
缓存一致性协议提供了一种高效的内存数据管理方案，它只会对单个缓存行（缓存行是缓存中数据存储的基本单元）的数据进行加锁，不会影响到内存中其他数据的读写。

缓存一致性协议（MESI）    
缓存一致性协议是一种缓存行状态管理机制,便于保证共享变量在CPU间的可见性.有MSI，MESI，MOSI，Synapse，Firefly及DragonProtocol等等，接下来我们主要介绍MESI协议。

MESI分别代表缓存行数据所处的四种状态，通过对这四种状态的切换，来达到对缓存数据进行管理的目的。

| 状态 | 描述 | 监听任务 | 
| ---- | ---- | ---- |
| M 修改（Modify） | 该缓存行有效，数据被修改了，和内存中的数据不一致，数据只存在于本缓存行中 | 缓存行必须时刻监听所有试图读该缓存行相对应的内存的操作，其他缓存须在本缓存行写回内存并将状态置为E之后才能操作该缓存行对应的内存数据 | 
| E 独享、互斥（Exclusive） | 该缓存行有效，数据和内存中的数据一致，数据只存在于本缓存行中 | 缓存行必须监听其他缓存读主内存中该缓存行相对应的内存的操作，一旦有这种操作，该缓存行需要变成S状态 | 
| S 共享（Shared） | 该缓存行有效，数据和内存中的数据一致，数据同时存在于其他缓存中 | 缓存行必须监听其他缓存是该缓存行无效或者独享该缓存行的请求，并将该缓存行置为I状态 | 
| I 无效（Invalid） | 该缓存行数据无效	 | 无 | 

备注：

```
1.MESI协议只对汇编指令中执行加锁操作的变量有效，表现到java中为使用voliate关键字定义变量或使用加锁操作
2.对于汇编指令中执行加锁操作的变量，MESI协议在以下两种情况中也会失效：
     一、CPU不支持缓存一致性协议。
     二、该变量超过一个缓存行的大小，缓存一致性协议是针对单个缓存行进行加锁，此时，缓存一致性协议无法再对该变量进行加锁，只能改用总线加锁的方式。
3. MESI协议只能保证并发编程中的可见性，并未解决原子性和有序性的问题，所以只靠MESI协议是无法完全解决多线程中的所有问题.
```

[缓存一致性协议分析](https://www.cnblogs.com/ynyhl/p/12119690.html)


#### synchronized

解决共享资源的原子性和有序性,因为是独占共享资源,所以不涉及可见性问题.

锁的表现形式:

```
普通方法->锁是当前示例对象
静态方法->锁是当前类的Class对象
同步方法块->锁是Synchronized指定的对象
```

synchronized要求线程访问同步代码块时,首先先获取锁,退出或异常时释放锁.

- 实现原理

JVM基于进入和退出Monitor对象来实现方法同步和代码块同步,两者实现细节不一样.    
代码块同步:使用monitorenter和monitorexit指令实现.    
方法同步的实现细节JVM规范中未提及,但是它可以使用代码块同步的方式来实现.

monitorenter: 在编译后插入到同步代码块的开始位置.
monitorexit:插入到方法结束或异常处.
JVM保证monitorenter和monitorexit成对匹配.任何对象都有一个monitor与之关联,当且一个monitor被持有后,它将处于锁定状态.     
线程执行到monitorenter指令时,将会尝试获取对象所对应的monitor的所有权,即尝试获取对象的锁.

![sychronized原理流程图](https://img2020.cnblogs.com/blog/443934/202012/443934-20201208134950492-2102954850.png)
- 对象头

Java的锁由对象实现,对象通过对象头来记录锁信息.对象头的格式如下:

![对象头格式](https://ask.qcloudimg.com/http-save/yehe-8916337/ed00955bbfbeac172f0095d5c21eee20.png?imageView2/2/w/1620)

HotSpot虚拟机中，对象在内存中存储的布局可以分为三块区域：对象头（Header）、实例数据（Instance Data）和对齐填充（Padding）.

从上面的这张图里面可以看出，对象在内存中的结构主要包含以下几个部分：

```
Mark Word(标记字段)：对象的Mark Word部分占4个字节，其内容是一系列的标记位，比如轻量级锁的标记位，偏向锁标记位等等。
Klass Pointer（Class对象指针）：Class对象指针的大小也是4个字节，其指向的位置是对象对应的Class对象（其对应的元数据对象）的内存地址
对象实际数据：这里面包括了对象的所有成员变量，其大小由各个成员变量的大小决定，比如：byte和boolean是1个字节，short和char是2个字节，int和float是4个字节，long和double是8个字节，reference是4个字节
对齐：最后一部分是对齐填充的字节，按8个字节填充。
```

- Mark Word(标记字段)

32位
```
|-------------------------------------------------------|--------------------|
|                  Mark Word (32 bits)                  |       State        |
|-------------------------------------------------------|--------------------|
| identity_hashcode:25 | age:4 | biased_lock:1 | lock:2 |       Normal       |
|-------------------------------------------------------|--------------------|
|  thread:23 | epoch:2 | age:4 | biased_lock:1 | lock:2 |       Biased       |
|-------------------------------------------------------|--------------------|
|               ptr_to_lock_record:30          | lock:2 | Lightweight Locked |
|-------------------------------------------------------|--------------------|
|               ptr_to_heavyweight_monitor:30  | lock:2 | Heavyweight Locked |
|-------------------------------------------------------|--------------------|
|                                              | lock:2 |    Marked for GC   |
|-------------------------------------------------------|--------------------|
```

64位
```
|------------------------------------------------------------------------------|--------------------|
|                                  Mark Word (64 bits)                         |       State        |
|------------------------------------------------------------------------------|--------------------|
| unused:25 | identity_hashcode:31 | unused:1 | age:4 | biased_lock:1 | lock:2 |       Normal       |
|------------------------------------------------------------------------------|--------------------|
| thread:54 |       epoch:2        | unused:1 | age:4 | biased_lock:1 | lock:2 |       Biased       |
|------------------------------------------------------------------------------|--------------------|
|                       ptr_to_lock_record:62                         | lock:2 | Lightweight Locked |
|------------------------------------------------------------------------------|--------------------|
|                     ptr_to_heavyweight_monitor:62                   | lock:2 | Heavyweight Locked |
|------------------------------------------------------------------------------|--------------------|
|                                                                     | lock:2 |    Marked for GC   |
|------------------------------------------------------------------------------|--------------------|
```

数据说明:
```
lock:2位的锁状态标记位，由于希望用尽可能少的二进制位表示尽可能多的信息，所以设置了lock标记。
biased_lock：对象是否启用偏向锁标记，只占1个二进制位。为1时表示对象启用偏向锁，为0时表示对象没有偏向锁。
age：4位的Java对象年龄。在GC中，如果对象在Survivor区复制一次，年龄增加1。当对象达到设定的阈值时，将会晋升到老年代。默认情况下，并行GC的年龄阈值为15，并发GC的年龄阈值为6。由于age只有4位，所以最大值为15，这就是-XX:MaxTenuringThreshold选项最大值为15的原因。
identity_hashcode：25位的对象标识Hash码，采用延迟加载技术。调用方法System.identityHashCode()计算，并会将结果写到该对象头中。当对象被锁定时，该值会移动到管程Monitor中。
thread：持有偏向锁的线程ID。
epoch：偏向时间戳。
ptr_to_lock_record：指向栈中锁记录的指针。
ptr_to_heavyweight_monitor：指向管程Monitor的指针。
```

- Monitor
Monitor 可以理解为一个同步工具或一种同步机制，通常被描述为一个对象。每一个 Java 对象就有一把看不见的锁，称为内部锁或者 Monitor 锁。

Monitor 是线程私有的数据结构，每一个线程都有一个可用 monitor record 列表，同时还有一个全局的可用列表。每一个被锁住的对象都会和一个 monitor 关联，同时 monitor 中有一个 Owner 字段存放拥有该锁的线程的唯一标识，表示该锁被这个线程占用。

Synchronized是通过对象内部的一个叫做监视器锁（monitor）来实现的，监视器锁本质又是依赖于底层的操作系统的 Mutex Lock（互斥锁）来实现的。而操作系统实现线程之间的切换需要从用户态转换到核心态，这个成本非常高，状态之间的转换需要相对比较长的时间，这就是为什么 Synchronized 效率低的原因。因此，这种依赖于操作系统 Mutex Lock 所实现的锁我们称之为重量级锁。


[对象头结构详情参考资料](https://www.cnblogs.com/hongdada/p/14087177.html)

- 锁升级

为了减少锁获取和释放带来的性能损耗,Java1.6对于锁进行了分类.引入了偏向锁,轻量级锁.    
锁状态:无锁状态,偏向锁状态,轻量级锁状态,重量级锁状态.状态会随着竞争情况逐渐升级.锁可以升级不能降级.    

分类:

1 无锁

无锁是指没有对资源进行锁定，所有的线程都能访问并修改同一个资源，但同时只有一个线程能修改成功。
无锁的特点是修改操作会在循环内进行，线程会不断的尝试修改共享资源。

2 偏向锁

初次执行到synchronized代码块的时候，锁对象变成偏向锁（通过CAS修改对象头里的锁标志位），字面意思是“偏向于第一个获得它的线程”的锁。执行完同步代码块后，线程并不会主动释放偏向锁。当第二次到达同步代码块时，线程会判断此时持有锁的线程是否就是自己（持有锁的线程ID也在对象头里），如果是则正常往下执行。由于之前没有释放锁，这里也就不需要重新加锁。如果自始至终使用锁的线程只有一个，很明显偏向锁几乎没有额外开销，性能极高。

偏向锁是指当一段同步代码一直被同一个线程所访问时，即不存在多个线程的竞争时，那么该线程在后续访问时便会自动获得锁，从而降低获取锁带来的消耗，即提高性能。

当一个线程访问同步代码块并获取锁时，会在 Mark Word 里存储锁偏向的线程 ID。在线程进入和退出同步块时不再通过 CAS 操作来加锁和解锁，而是检测 Mark Word 里是否存储着指向当前线程的偏向锁。轻量级锁的获取及释放依赖多次 CAS 原子指令，而偏向锁只需要在置换 ThreadID 的时候依赖一次 CAS 原子指令即可。

偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁，线程是不会主动释放偏向锁的。

关于偏向锁的撤销，需要等待全局安全点，即在某个时间点上没有字节码正在执行时，它会先暂停拥有偏向锁的线程，然后判断锁对象是否处于被锁定状态。如果线程不处于活动状态，则将对象头设置成无锁状态，并撤销偏向锁，恢复到无锁（标志位为01）或轻量级锁（标志位为00）的状态。

3 轻量锁/自旋锁

![轻量锁](https://img-blog.csdnimg.cn/20200606123648335.png)

4 重量级锁

轻量锁存在竞争时,未抢到锁的线程会进行自旋处理,自旋一定次数后还是没获取到锁，说明竞争激烈，接下来膨胀为重量级锁.    
![synchronized锁结构](https://pics5.baidu.com/feed/b58f8c5494eef01f7a3a8654caf0192cbc317d08.jpeg?token=cd61c63ac8ea22d8403505cbf65814dd)

[锁分类参考资料](https://www.cnblogs.com/mingyueyy/p/13054296.html)

- 各种锁的优缺点对比

! 锁 | 优点 | 缺点 | 使用场景 | 
| ---- | ---- | ---- | ---- | 
| 偏向锁 | 加锁和解锁不需要额外的消耗,锁成本在纳秒级 | 若锁竞争时会有额外的锁撤销消耗 | 只有一个线程 |
| 轻量级锁 | 不阻塞竞争线程,提高程序响应速度 | 如果始终得不到锁竞争的线程,使用自旋会消耗CPU | 追求响应速度,同步块执行速度非常快 |
| 重量级锁 | 线程竞争不使用自旋,不会消耗CPU | 线程阻塞,响应时间缓慢 | 追求吞吐量,同步块执行速度较长 |

#### 原子操作

原子操作(atomic operation): 不可被中断的一个或一系列操作.    
1 CPU会自动保证基本的内存操作的原子性    
2 自动保证单处理器对同一个缓存行里进行16/32/64位操作是原子的

但是跨总线,跨缓存行,跨页表无法自动保证原子性,因此CPU提供了两种机制保证原子性:

机制一: 使用总线锁保证原子性.多CPU间通过LOCK信号来控制独享共享变量    
机制二: 使用缓存锁保证原子性.基于缓存一致性协议实现内存地址的独享

不使用缓存锁定的场景:
1 数据不能被CPU缓存或者跨缓存行时.使用总线锁    
2 CPU不支持缓存锁.

- JAVA的原子操作

实现方式两种: 锁,循环CAS

循环CAS

比如1.5后的并发包里原子操作类.

CAS的三大问题:
```
1 ABA问题.存在痕迹覆盖的问题.追加版本号来增加操作痕迹
2 循环时间长开销大.
3 只能保证一个共享变量的原子操作.合并共享变量+JDK并发包工具类
```

锁

锁机制保证了只有获得锁的线程才能够操作锁定的内存区域

### Java内存模型

并发编程模型的两个关键问题:

1 线程间如何通信

通信:指信息交换机制.     
通信机制:共享内存和消息传递    
```
共享内存:共享程序的公共状态,通过写-读内存中的公共状态进行隐式通信    
消息传递:线程间没有公共状态,线程间必须通过发送消息显式进行通信
```

2 线程间如何同步

同步: 程序中控制不同线程间操作发生相对顺序的机制.    

共享内存: 显示同步    
消息传递: 隐式同步

- Java内存模型的抽象结构

jvm结构
![jvm结构](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/1c1d85b5fb8b47239af2a5c0436eb2d7-new-image0cd10827-2f96-433c-9b16-93d4fe491d88.png)

[参考资料](https://zhuanlan.zhihu.com/p/25713880)

所有实例域,静态域,数组元素都存储在堆内存中.堆内存在线程间共享.    
局部变量,方法定义参数和异常处理器参数不会在线程间共享.栈    
Java内存模型用于定义共享变量,作用范围在堆内存中.

Java线程间通信由Java内存模型(JMM)控制,JMM决定一个线程对共享变量的写入何时对另一个线程可见.    
JMM定义了线程和主内存间的抽象关系: 线程间的共享变量存储在主内存中,每个线程都有一个私有的本地内存.    
本地内存存储了该线程以读/写共享变量的副本.本地内存是一个抽象概念,并不真实存在.实际涵盖了缓存,写缓冲区,寄存器及其他硬件和编译优化器    

Java内存模型抽象机构:

![Java内存模型抽象机构](https://pic3.zhimg.com/80/v2-4fa35004d158151b4738792bf5bb49ca_720w.jpg)

线程间通信流程:(以线程A向B线程通信为例)

1 线程A把线程本地内存中更新过的共享变量刷新到主内存中    
2 线程B到主内存中读取线程A更新到主内存中变量

- 指令重排序(线程共享变量准确性的影响因素)

为了提高性能,编译器和处理器常对指令做重排序,分为三种:    
1 编译器优化的重排序.编译器在不改变单线程程序语义的前提下,可以重新安排语句执行顺序.    
2 指令级并行的重排序.CPU重排序.CPU采用指令级并行技术来将多条指令重叠执行.如果数据不存在数据依赖性,CPU可以改变语句对应机器指令的执行顺序.    
3 内存系统的重排序.CPU重排序.CPU使用缓存的读写缓冲区,这使得加载和存储操作实际可能是乱序执行.    

程序执行顺序:

源代码 -> 编译器优化重排序 -> 指令级并行重排序 -> 内存系统重排序 -> 最终执行的指令序列

重排序可能会导致多线程程序出现内存可见性问题.JMM确保对多线程提供一致的内存可见性.     
编译器重排序.JMM会禁止特定类型的编译器重排序;
CPU重排序.会要求Java编译器在生成指令时,对CPU重排序插入特点类型的**内存屏障**指令,通过内存屏障指令来禁止特定类型的CPU重排序.



#### happens-before 

happens-before 来明确操作间的可见性.JMM中,如果一个操作执行的结果需要对另一个操作可见,那么这两个操作间必须要存在happens-before关系.
JMM通过happens-before 关系向程序员提供跨线程的内存可见性保证.

JSR-133对happens-before 关系的定义如下:

1 如果一个happens-before另一个操作,那么第一个操作的**执行结果**将对第二个操作可见,而且第一个操作的执行顺序排在第二个操作之前.(JMM对程序员的承诺)    
2 两个操作之间存在happens-before 关系,并不意味Java平台的具体实现必须要按happens-before关系指定的顺序来执行.(JMM对编译器和处理器重排序的约束原则)

happens-before关系保证正确同步的多线程程序的执行结果不被改变.

happens-before规则:

```
程序顺序规则: 一个线程中的每个操作,happens-before于该线程中的任意后续操作.    
监视器锁规则: 对一个锁的解锁,happens-before 于随后对这个锁的加锁.    
volatile变量规则: 对一个volatile域的写,happens-before 于任意后续对这个volatile 域的读.    
传递性: 如果A happens-before B,且B happens-before C,那么A happens-before C    
start()规则: 线程A执行ThreadB.start(),那么线程A.start() happens-before 于线程B的任意操作    
join()规则: 线程A执行ThreadB.join(),那么线程B的任意操作 happens-before于线程A的从ThreadB.join()操作成功返回
```

**happens-before: 仅要求前一个操作(的执行结果)对后一个操作可见且前一个操作按顺序排在第二个操作之前.并不要求前一个操作必须要在后一个操作之前执行.**    
核心原则: happens-before不要求前一个操作和后一个操作的发生顺序,  仅仅要求前一个操作的执行完成并刷新回内存发生在后一个操作结果之前.所以happens-before只发生在跨CPU或跨线程间.它只要求最终结果,不限制中间过程,尽可能减少对于编译器和处理器的限制,同时也不影响程序员使用的简单性.

happens-before 是JMM最核心的概念.JMM 两个设计关键因素:
```
1 程序员对内存模型的使用.使用越简单越好    
2 编译器和处理器对内存模型的实现.限制越少越好    
```
如果要简单就要多限制编译器和处理器;如果要限制少,易用性就降低.    
而happens-before就是满足上面两个因素的设计规则:    

核心规则:

1 禁止编译器和处理器重排序会改变程序结果的重排序    
2 不限制不会改变程序结果的重排序


#### 重排序

重排序: 指编译器和CPU为了优化程序性能而对指令序列进行重新排序的一种手段.

- 数据依赖性

数据依赖性: 指两个操作访问同一个变量,且两个操作中有一个写操作的关系.

分类:

```
写后读    
写后写   
读后写
```

这三种情况,只有重排序两个操作的顺序,执行结果就会改变.编译器和CPU不会改变存在数据依赖性的两个操作的执行顺序.    
这里所说的数据依赖性仅针对单个处理器中执行的指令序列和单个线程中的执行操作,跨处理器和跨线程的数据依赖性不被编译器和CPU考虑.    

- as-if-serial语义

as-if-serial语义: 不管怎么重排序,单线程程序的执行结果不能被改变.编译器,runtime,CPU都必须遵守该语义,不会对存在数据依赖性的操作进行重排序.

as-if-serial语义使程序员无需担心单线程下的重排序干扰结果,无需担心内存可见性问题.

- 程序顺序规则(传递性)

A happens-before B    
B happens-before C    
所以 A happens-before C    


软件技术和硬件技术的共同目标: 在不改变程序执行结果的前提下,尽可能提高并行度

单线程中,对于存在控制依赖的操作重排序,不会改变执行结果(as-if-series保证);    
多线程中,对存在控制依赖的操作重排序,可能会改变程序的执行结果

#### 顺序一致性

数据竞争: 在一个线程中写一个变量,在另一个线程读同一个变量,而且写和读没有通过同步来排序.    
如果程序是正确同步的,程序的执行将具有顺序一致性,即程序的执行结果与该程序在顺序一致性内存模型中的执行结果相同.这里的同步是广义的同步,包括同步原语synchronized,volatile,final的正确使用.

顺序一致性内存模型是一个理论参考模型,为程序员提供极强的内存可见性保证.两大特性如下:     
1 一个线程中的所有操作必须按照程序的顺序来执行    
2 不管程序是否同步,所有线程都只能看到一个单一的操作执行顺序.每个操作都必须原子执行且立刻对所有线程可见.

在概念上,顺序一致性模型有一个单一的全局内存,这个内存通过一个左右摆动的开关可以连接到任意一个线程,同时每一个线程必须按照程序来执行内存读/写操作.在任意时间点最多只能有一个线程可以连接到内存.多线程并发执行时,所有线程的所有内存读写操作时串行化的,所有操作之间是有序关系.

但JMM没有顺序一致性的保证,未同步程序在JMM中不但整体的执行顺序是无序的,而且所有线程看到的操作执行顺序也可能不一致.其他线程对于内存共享变量的可见性与共享变量从线程缓存刷新到主内存的时点直接关联,而与共享变量的实际执行时间没有强关联.**这个也是happens-before规则的价值所在**

- 同步程序的顺序一致性

顺序一致性模型完全是串行执行.而在JMM中,临界区内的代码可以重排序.由于监视器互斥执行,其他线程无法获取临界区内重排序信息.这样即提高了执行效率,又没有改变程序的执行结果.    
JMM的基本原则: 在不改变程序执行结果的前提下,尽可能地支持编译器和处理器的优化.

- 未同步程序的执行特性

JMM不保证未同步程序的执行结果与该程序在顺序一致性模型中的执行结果一致.未同步程序在JMM中的执行时,整体上是无序的,其执行结果无法预知.    
1 顺序一致性模型保证单线程内的操作会按程序的顺序执行,而JMM不保证单线程内的操作会按程序的顺序执行.如重排序与数据依赖关系    
2 顺序一致性模型保证所有线程只能看到一致的操作执行顺序,而JMM不保证所有线程能看到一致的操作执行顺序.    
3 JMM不保证对64位long型,double型变量的写操作原子性,而顺序一致性模型保证对所有的内存读/写操作都具有原子性    

总线事务: 每次处理器和内存间的数据传递的一系列步骤.读事务:从内存传送数据到处理器;写事务:从处理器传送数据到内存.在总线事务中,处理器会同步试图并发使用总线的事务.在一个处理器执行总线事务期间,总线会禁止其他处理器和I/O设备执行内存的读/写.    
总线事务机制可以把所有处理器对内存的访问串行化执行.在任意时间点,最多只有一个处理器可以访问内存.保证了单个总线事务中的内存读/写操作具有原子性.

JSR-133(JDK1.5开始)内存模型要求只允许64long/double变量的写操作拆分为两个32位的写操作执行,任意读操作必须具有原子性.

#### volatile

可以将对volatile变量的单个读/写理解为使用同一个锁对这些单个读/写操作做了同步.    
   
特性:    
1 可见性.对一个volatile变量的读,总能看到任意线程对这个volatile变量的写(锁的happens-before 规则保证释放锁和获取锁的两个线程之间的内存可见性).    
2 原子性.对任意单个volatile变量的读/写具有原子性(锁的语义决定了临界区代码的执行具有原子性).

- volatile写-读建立的happens-before关系

从JSR-133(JDK1.5)开始,volatile变量的写-读可以实现线程间的通信    
从内存语义的角度来说,volatile的写-读与锁的释放和获取有相同的内存效果.volatile写和锁的释放有相同的内存语义;volatile读与锁的获取有相同的内存语义

volatile与happens-before的关系    
![volatile与happens-before](http://img.mp.sohu.com/upload/20170628/e9254d8e0617447e8fbfe7bb22d9e455_th.png)

- volatile写-读的内存语义

volatile写的内存语义: 当写一个volatile变量时,JMM会把该线程对应的本地内存中的共享变量值刷新到主内存    
volatile读的内存语义: 当读一个volatile变量时,JMM会把该线程对应的本地内存置为无效.线程将从主内存中读取共享变量.

每一次volatile写读都是一次线程间的消息传递过程.

- volatile内存语义的实现

volatile重排序规则表    
![](https://pics6.baidu.com/feed/b812c8fcc3cec3fdbaf8737e476cc736859427e0.png?token=def69ab39916e73355428cadde3ae425)

不对volatile读之后的任何操作重排序;不对volatile写之前的任何操作重排序.    
不对volatile写之后的volatile变量操作进行重排序

为了实现volatile的内存语义,编译器在生成字节码时,会在指令序列中插入内存屏障来禁止特定类型的处理器重排序

JMM基于保守策略来插入内存屏障:

```
在每个volatile写操作的前面插入一个StoreStore屏障(禁止普通写与volatile写重排序)    
在每个volatile写操作的后面插入一个StoreLoad屏障(禁止volatile写与volatile读写重排序)    
在每个volatile读操作的后面插入一个LoadLoad屏障(禁止普通读与volatile读重排序)    
在每个volatile读操作的后面插入一个LoadStore屏障(进行普通写与volatile读重排序)    
```

实际执行时,编译器根据要执行的代码省略不必要的内存屏障,来优化实际执行的代码

> 内存屏障类型

![](https://pics4.baidu.com/feed/a6efce1b9d16fdfa4169cec75dccf75394ee7b59.jpeg?token=e2153ef2a6938c4f8704d80674160be0)

StoreLoad 是一个全能型屏障,它同时具体其他三种屏障效果.它的开销也很大,当前CPU需要把写缓冲区中的数据全部刷新到内存中.    
Store是写,Load是读.

- JSR-133 增强volatile内存语义的原因

JSR-133 前的Java内存模型不允许volatile变量间重排序,但允许volatile变量和普通变量重排序.普通变量的重排序会造成其他线程获取变量结果的不可知.
所以JSR-133增强了volatile内存语义:    
严格限制编译器和处理器对volatile变量与普通变量的重排序,确保volatile的写-读和锁的释放-获取具有相同的内存语义.

```
在功能上,锁比volatile更强大;在可伸缩性和执行性能上,volatile更好;
```

[volatile原理简介](https://juejin.cn/post/6844903601064640525)

#### 锁的内存语义

锁的释放-获取建立的happens-before关系

锁是Java最重要的同步机制.锁除了让临界区互斥执行外,还可以让释放锁的线程向获取同一个锁的线程发送消息(获取到内存共享变量).线程A在锁释放前所有可见的共享变量,在线程B获取同一个锁后,将立即对线程B可见

- 锁的释放-获取内存语义

当线程释放锁时,JMM会把该线程对应的本地内存中的共享变量刷新到主内存中.    
当线程获取锁时,JMM会把该线程对应的本地内存置为无效.从而使得被监视器保护的临界区代码必须从主内存中读取共享变量    
所以: 锁释放与volatile写有相同的内存语义;锁获取与volatile读有相同的内存语义

即:    
```
线程A释放锁,实质上是线程A向接下来将要获取这个锁的某个线程发出了消息    
线程B获取锁,实质上是线程B接收了之前某个线程发出的消息    
线程A释放锁,线程B获取锁,实质上是线程A通过主内存向线程B发送消息
```

- 锁的实现

ReentrantLock 锁结构:    
![](https://pics6.baidu.com/feed/e824b899a9014c084d66fe196703a9007af4f4aa.png?token=0d2197b9ad1f4a2d2360b1f4fa879d74)

以公平锁为例,ReentrantLock.lock() 加锁方法调用轨迹:    
1 ReentrantLock.lock()    
2 FairSync.lock()    
3 AbstractQueuedSynchronier.acquire(int arg)    
4 ReentrantLock.tryAcquire(int acquires)

tryAcquire实现:    
```
 protected final boolean tryAcquire(int acquires) {
             final Thread current = Thread.currentThread();
             //获取状态位
             int c = getState();
             //0，锁还没被拿走
             if (c == 0) {
                 //如果队列中没有其他线程 说明没有线程正在占有锁
                 if (!hasQueuedPredecessors() &&
                     //修改状态为1
                     compareAndSetState(0, acquires)) {
                     //如果通过CAS操作将状态为更新成功则代表当前线程获取锁，
                     //因此，将当前线程设置到AQS的一个变量中，说明这个线程拿走了锁。
                     setExclusiveOwnerThread(current);
                     return true;
                 }
             }
             //锁被拿走了，由于ReentrantLock是可重入锁，所以判断下持有锁的是否是同一个线程
             else if (current == getExclusiveOwnerThread()) {
                 //如果是的话累加在state字段上就可以了
                 int nextc = c + acquires;
                 if (nextc < 0)
                     throw new Error("Maximum lock count exceeded");
                 setState(nextc);
                 return true;
             }
             return false;
         }
     }
```
加锁方法首先读volatile变量state


公平锁中,ReentrantLock.unlock()调用轨迹:    
1 ReentrantLock.unlock()    
2 AbstractQueuedSynchronizer.release(int arg)    
3 Sync.tryRelease(int releases)
```
protected final boolean tryRelease(int releases) {
    int c = getState() - releases;
    if (Thread.currentThread() != getExclusiveOwnerThread())
        throw new IllegalMonitorStateException();
    boolean free = false;
    if (c == 0) {
        free = true;
        setExclusiveOwnerThread(null);
    }
    setState(c);
    return free;
}
```
释放锁时最后写volatile变量state    

CAS: compareAndSet(int expect,int update).如果当前状态值等于预期值,则以原子方式将同步状态设置为给定的更新值.CAS操作具有volatile读和写的内存语义.

编译器不会对volatile读与volatile读后面的任意内存操作重排序;编译器不会对volatile写与volatile写前面的任意内存操作重排序.组合这两个条件,意味着为了同时实现volatile读和volatile写的内存语义,编译器不能对CAS与CAS前面和后面的任意内存操作重排序.

具体实现:    
如果是多核处理器,程序会在cas中为特定指令增加lock前缀.单核处理器会省略lock前缀.    
lock前缀含义:     
1 确保对内存的读-改-写操作原子执行.总线锁,缓存锁    
2 禁止该指令,与之前和之后的读和写指令重排序    
3 把写缓冲区中的所有数据刷新到内存中    

上面2,3具有内存屏障效果,等同于volatile读和volatile写的内存语义.    

公平锁和非公平锁的内存语义:    
1 两者锁释放时,最后都要写一个volatile变量stage    
2 公平锁获取时,首先读volatile变量    
3 非公平锁获取时,首先会用CAS更新volatile变量,这个操作同时具备volatile读和volatile写内存语义    

因此锁释放-获取的内存语义实现方式至少有两种:    
1 利用volatile变量的写-读所具有的内存语义     
2 利用CAS所附带的volatile读和volatile写的内存语义


- concurrent 包的实现

concurrent 包的基石: CAS原子指令 + volatile读写和CAS实现线程间通信

concurrent 包的实现模式:    
首先,声明共享变量为volatile    
其次,使用CAS的原子条件更新来实现线程之间的同步   
同时,配合以volatile读/写和CAS所具有的volatile读/写内存语义来实现线程之间的通信

AQS的非阻塞数据结构和原子变量类,这些concurrent 包中的基础类都是使用这种模式来实现的,而concurrent 包中的高层类又是依赖这些基础类来实现的


#### final 域的内存语义

final域中,编译器和处理器要遵守两个重排序规则:    
1 在构造函数内对一个final域的写入,与随后把这个被构造对象的引用赋值给一个引用变量,这两个操作间不能重排序.    
2 初次读一个包含final域的对象的引用,与随后初次读这个final域,这两个操作之间不能重排序

- 写final域的重排序规则

写final域的重排序规则禁止把final域的写重排序到构造函数之外:    
1 JMM禁止编译器把final域的写重排序到构造函数之外.    
2 JMM禁止编译器把final域的写之后,构造函数return之前,插入一个StoreStore屏障.这个屏障禁止处理器把final域的写重排序到构造函数之外.    

写final域重排序规则确保: 在对象引用被任意线程可见之前,对象的final域已经被正确初始化过了,而普通域不具有这个保障    

为什么final引用不能从构造函数内"溢出"?    
写final域重排序规则保证了对象的final域正确被初始化,它其实还需要一个约束条件: 在构造函数内部,不能让这个被构造对象的引用被其他线程可见,也就是对象引用不能在构造函数中"溢出".    
因为构造函数内部也存在重排序,如果内部存在被外部可见的对象引用,可能造成对象读取到未正常初始化的值,进而引起程序不唯一结果.


多线程间final域与普通域的可见性问题:    
![](https://img2018.cnblogs.com/blog/1604211/201905/1604211-20190519201937300-548550293.png)


- 读final域的重排序规则

读final域的重排序规则: 在一个线程中,初次读对象引用与初次读该对象包含的final域,JMM禁止处理器重排序这两个操作(仅针对处理器).编译器会在读final域操作的前面插入一个LoadLoad屏障.    

初次读对象引用与初次读该对象包含的final域,这两个操作存在间接依赖关系.编译器遵守间接依赖关系,它不会重排序这两个操作.大多数处理器也会遵守间接依赖,而少数处理器(alpha)允许对间接依赖重排序,这个规则就是来限制这些处理器的.

读final域的重排序规则确保: 在读一个对象的final域之前,一定会先读包含这个final域的对象的引用.

- final域为引用类型

对于引用类型,写final域的重排序规则对编译器增加了约束:    
在构造函数内对一个final引用的对象的成员域的写入,与随后在构造函数外把这个被构造对象的引用赋值给一个引用变量,这两个操作间不能重排序.


> JSR-133增强final语义
通过为final域增加写和读重排序规则,可以为Java程序员提供初始化安全保证: 只要对象是正确构造的(被构造对象的引用在构造函数中没有"溢出"),那么不需要使用同步(lock,volatile)就可以保证任意线程都能看到这个final域在构造函数中被初始化之后的值.

#### 双重检查锁定与延迟初始化

在Java多线程中,有时候可能需要推迟一些高开销的对象初始化操作,并且只有在使用这些对象时才进行初始化.

- 双重检查锁定

双重检查锁定就是懒加载的一种实现方式:    

```
public class DoubleCheckedLocking {                 //1
    private static Instance instance;                    //2

    public static Instance getInstance() {               //3
        if (instance == null) {                          //4:第一次检查
            synchronized (DoubleCheckedLocking.class) {  //5:加锁
                if (instance == null)                    //6:第二次检查
                    instance = new Instance();           //7:问题的根源出在这里
            }                                            //8
        }                                                //9
        return instance;                                 //10
    }                                                    //11
}                                                        //12
```

这种方式用于解决直接方法锁的性能问题,但第4步instance不为null时,instance引用的对象有可能还没有完成初始化.因为instance = new Instance() 这个步骤可能发送重排序.

instance = new Instance() 内存语义:    
```
memory = allocate();   //1：分配对象的内存空间
ctorInstance(memory);  //2：初始化对象
instance = memory;     //3：设置instance指向刚分配的内存地址
```

2,3步骤会发生重排序.所有线程在执行java程序时必须要遵守intra-thread semantics。intra-thread semantics保证重排序不会改变单线程内的程序执行结果。换句话来说，intra-thread semantics允许那些在单线程内，不会改变单线程程序执行结果的重排序。上面三行伪代码的2和3之间虽然被重排序了，但这个重排序并不会违反intra-thread semantics。这个重排序在没有改变单线程程序的执行结果的前提下，可以提高程序的执行性能。因为单线程中只有初始化完成,才会被外部访问,所以2,3重排序不影响最终结果

但是多线程环境中就会出现访问到未正常初始化的对象:

![](https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fimg.136.la%2F20200924%2Fce90e907794c420c9b81147c31c9208a.jpg&refer=http%3A%2F%2Fimg.136.la&app=2002&size=f9999,10000&q=a80&n=0&g=0n&fmt=auto?sec=1658139891&t=f7d84da4696a24c19176c7dcb6ceadf9)


解决方式:    
1 不允许2,3重排序    
2 允许2,3重排序,但不允许其他线程"看到"这个重排序

- 基于volatile解决延迟初始化重排序问题

```
public class DoubleCheckedLocking {                 //1
    private volatile static Instance instance;                    //2 增加volatile语义

    public static Instance getInstance() {               //3
        if (instance == null) {                          //4:第一次检查
            synchronized (DoubleCheckedLocking.class) {  //5:加锁
                if (instance == null)                    //6:第二次检查
                    instance = new Instance();           //7:问题的根源出在这里
            }                                            //8
        }                                                //9
        return instance;                                 //10
    }                                                    //11
}                                                        //12
```
volatile变量禁止volatile变量读之后的任何重排序操作,这样就可以解决多线程间由于重排序造成的结果不一致问题

- 基于类初始化的解决方案

```
public class InstanceFactory {
     private static class InstanceHolder {
          public static Instance instance = new Instance();
     }
     public static Instance getInstance() {
          return InstanceHolder.instance;   //触发instance进行初始化
     }
}
```
JVM在类的初始化阶段(即在Class被加载后,且被线程使用之前),会执行类的初始化.在执行类的初始化期间,JVM会去获取一个锁,用于同步多线程间对同一个类的初始化.    
初始化中2,3步骤可以重排序,但是共享变量临界区内的值只有在释放锁时才能被其他线程可见,所以重排序不影响结果的一致性

类,接口的初始化时点:    
1 T是一个类,而且一个T类型的实现被创建     
2 T是一个类,且T中声明的一个静态方法被调用    
3 T中声明的一个静态字段被赋值    
4 T中声明的一个静态字段被使用,而且这个字段不是一个常量字段    
5 T是一个顶级类,而且一个断言语句嵌套在T内部被执行

类接口的初始化存在并发问题(创建步骤非原子性),所以多线程中需要同步处理.Java语言规范规定:    
对于每一个类或接口C,都有一个唯一的初始化锁LC与之对应.从C到LC的映射,由JVM的具体实现去自由实现.    
JVM在类初始化期间会获取这个初始化锁,并且每个线程至少获取一次锁来确保这个类已经被初始化过了.

初始化类或接口的核心流程:    
1 通过在Class对象上同步(即获取Class对象的初始化锁),来控制类或接口的初始化.这个获取锁的线程会一直等待,直到当前线程能够获取到这个初始化锁(获取到锁的线程将锁对象状态由onInitialization改为initializing)        
2 线程A执行类的初始化(执行类静态初始化和初始化类静态字段),同时线程B在初始化锁对应的condition上等待    
3 线程A设置state=initialized,然后唤醒在condition中等待的所有线程.    
4 线程B结束类的初始化处理


基于volatile与基于类的初始化方案的优缺点:    
```
优点:    
1 基于volatile可实现静态字段和实例字段的双层延迟处理;    
2 基于类的初始化实现方式更简洁,可读性好    
缺点:    
延迟处理类初始化成本较正常初始化要高.它虽然推迟了类创建实例开销,但是增加了访问延迟初始化的字段开销.
```

#### Java内存模型

JMM和处理器内存模型在设计时通常会以顺序一致性内存模型为参考.在设计时,会对顺序一致性模型的实现有所放松,来实现一致性和可用性,效率的兼容.    

根据对不同类型的读写操作组合的执行顺序的放松,常见处理器的内存模型分类:    
```
1 TSO(Total Store Ordering).放松程序中写-读操作的顺序    
2 PSO(Partial Store Order).在TSO上,继续放松程序中写-写的操作顺序    
3 RMO(Relaxed Memory Order)和PowerPC.在前两条下,继续放松程序中读-写和读-读的操作顺序 
```
这里的放松指两个操作间不存在数据依赖性为前提的.处理器要遵守as-if-serieal语义,不对存在数据依赖的内存操作做重排序.

处理器内存模型的特征表:    
![](https://img-blog.csdnimg.cn/115df4e6ce4248ba9e769d420a523048.png)

所有处理器都支持写-读操作重排序.因为处理器支持写缓存区,实际的内存操作写先执行在缓存区中,对外可见的内存操作读往往先发生,然后当缓存刷新时才会将写操作更新到主内存中,所以读写的重排序被处理器支持.    
由于缓存区的存在,写操作可以先被当前处理器可见    
上图中从上到下,模型由强变弱.越是追求性能的处理器,内存模型设计越弱.    
而常见的处理器内存模型比JMM要弱,Java编译器在生成字节码时,会在执行指令序列的适当位置插入内存屏障来限制处理器的重排序.    
JMM屏蔽了不同处理器内存模型的差异,它在不同的处理器平台上为Java程序员呈现了一个一致的内存模型


- JMM的内存可见性保证

1 单线程程序.不会出现内存可见性问题,由编译器,runtime,处理器共同保证    
2 正确同步多线程程序.JMM核心价值就是保障这点.JMM通过限制编译器和处理器重排序来保障内存可见性    
3 未同步/未正确同步的多线程程序.JMM提供最小安全性保障: 线程执行时读取到的值,要么是之前某个线程写入的值,要么是默认值(默认初始化值),用于保证线程读取值不会无中生有,但不保证值的准确性    

- JSR-133对JMM的增强点

1 增强volatil内存语义.严格限制volatile变量与普通变量的重排序,使volatile的写-读和锁的释放-获取具有相同的内存语义       
2 增强final内存语义.旧内存模型中,多次读取同一个final变量的值可能会不相同.JSR-133为此增加了两个重排序规则(增加final域写和读重排序规则),在保证final引用不会从构造函数逸出的情况下,final正确初始化















### 扩展阅读

[面试基础准备](https://javaguide.cn/java/jvm/jvm-intro.html#_1-1-java%E6%96%87%E4%BB%B6%E6%98%AF%E5%A6%82%E4%BD%95%E8%A2%AB%E8%BF%90%E8%A1%8C%E7%9A%84)


